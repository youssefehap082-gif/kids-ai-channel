"""
scripts/pipeline_runner.py
Simple orchestrator / runner for a single pipeline execution (one long video).
This is a scaffold: it calls the generator -> (placeholder) tts -> (placeholder) fetch media -> (placeholder) render -> upload (stub).
It demonstrates config-driven operation and error handling.
"""

import os
import json
import logging
from datetime import datetime

from scripts.generate_script import generate_facts
# Note: tts, media, render, upload implementations are placeholders/stubs for now.
# They should be replaced with your real implementations (elevenlabs sdk, ffmpeg render, youtube upload library)

logger = logging.getLogger("kids_ai.pipeline")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)


def load_channel_config(path=None):
    if not path:
        path = os.path.join(os.path.dirname(__file__), "..", "config", "channel_config.json")
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.warning("Could not load channel_config.json: %s. Using defaults.", e)
        return {"default_language": "en"}


# --- placeholder steps --- #
def tts_generate_script(facts: list, voices: list):
    """
    Placeholder: generate TTS files for each fact
    Returns list of local audio paths or bytes placeholders.
    """
    logger.info("Generating TTS for %d facts (placeholder). Voices: %s", len(facts), voices)
    audios = [f"/tmp/fact_{i}.wav" for i in range(len(facts))]
    # in production do real TTS and save files
    return audios


def fetch_media_for_facts(facts: list, limit_per_fact=2):
    """
    Placeholder: fetch images / clips for each fact.
    Returns dict fact_index -> list of asset URLs or local paths
    """
    logger.info("Fetching media placeholder for %d facts", len(facts))
    media_map = {i: [f"https://example.com/placeholder_{i}.jpg"] for i in range(len(facts))}
    return media_map


def render_video(facts: list, audios: list, media_map: dict, out_path: str):
    """
    Placeholder render: simply writes a small JSON as "render output".
    Replace with real video builder (ffmpeg + templates).
    """
    logger.info("Rendering video placeholder to %s", out_path)
    render_meta = {
        "facts": facts,
        "audios": audios,
        "media": media_map,
        "timestamp": str(datetime.utcnow())
    }
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(render_meta, f, ensure_ascii=False, indent=2)
    return out_path


def upload_video(file_path: str, meta: dict):
    """
    Placeholder uploader. In production integrate with YouTube Data API (OAuth2).
    """
    logger.info("Uploading file placeholder %s. meta keys: %s", file_path, list(meta.keys()))
    # return a simulated youtube id and url
    return {"status": "uploaded", "video_id": "VIDEO12345", "url": f"https://youtu.be/VIDEO12345"}


# --- pipeline runner --- #
def run_pipeline(topic: str, desired_facts: int = 10, output_dir: str = "/tmp"):
    logger.info("Pipeline start for topic=%s", topic)
    channel_conf = load_channel_config()
    providers_used = []

    try:
        gen_result = generate_facts(topic, desired=desired_facts)
        facts = gen_result.get("facts", [])
        providers_used = gen_result.get("provider_chain", [])
        logger.info("Generated %d facts using providers=%s", len(facts), providers_used)

        if not facts:
            raise RuntimeError("No facts generated; aborting pipeline.")

        # TTS
        voices = channel_conf.get("tts_voices", ["eleven_male", "eleven_female"])
        audios = tts_generate_script(facts, voices)

        # media
        media_map = fetch_media_for_facts(facts)

        # render
        os.makedirs(output_dir, exist_ok=True)
        out_file = os.path.join(output_dir, f"render_{topic.replace(' ', '_')}_{int(datetime.utcnow().timestamp())}.json")
        render_path = render_video(facts, audios, media_map, out_file)

        # upload
        meta = {"title": f"{topic} â€” 10 Facts", "description": "Auto-generated by kids-ai-pipeline"}
        upload_res = upload_video(render_path, meta)

        # logs
        run_log = {
            "topic": topic,
            "facts_count": len(facts),
            "providers": providers_used,
            "render_path": render_path,
            "upload": upload_res,
            "ts": str(datetime.utcnow())
        }
        logger.info("Pipeline finished: %s", upload_res.get("status"))
        return run_log

    except Exception as e:
        logger.exception("Pipeline failed: %s", e)
        # Import and call error_recovery if present (non-fatal)
        try:
            from scripts.error_recovery import recover_from_exception
            recover_from_exception(e, context={"topic": topic})
        except Exception as rec_e:
            logger.warning("Error recovery failed or not present: %s", rec_e)
        raise


# allow CLI runs for quick tests
if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument("--topic", required=True)
    p.add_argument("--n", type=int, default=10)
    p.add_argument("--out", default="/tmp")
    args = p.parse_args()
    res = run_pipeline(args.topic, desired_facts=args.n, output_dir=args.out)
    print(json.dumps(res, indent=2, ensure_ascii=False))
