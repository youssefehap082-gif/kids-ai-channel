import os
import requests
import json
import random
import datetime
from googleapiclient.discovery import build

from dotenv import load_dotenv
from utils import get_video_stats, get_trending_animals

load_dotenv()

YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

def get_youtube_trending_animals():
    """
    Ø¨ÙŠØ¬ÙŠØ¨ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù„ÙŠ Ø·Ø§Ù„Ø¹Ø© ØªØ±ÙŠÙ†Ø¯ Ù…Ù† Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨
    """
    try:
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        request = youtube.videos().list(
            part="snippet,statistics",
            chart="mostPopular",
            regionCode="US",
            videoCategoryId="15",  # category: Pets & Animals
            maxResults=30
        )
        response = request.execute()

        trending = []
        for item in response.get("items", []):
            title = item["snippet"]["title"].lower()
            if any(animal in title for animal in [
                "cat", "dog", "lion", "tiger", "bear", "snake",
                "fish", "elephant", "bird", "wolf", "horse",
                "panda", "monkey", "fox", "shark", "dolphin"
            ]):
                trending.append(title)
        print(f"âœ… YouTube trending animals found: {len(trending)}")
        return trending
    except Exception as e:
        print(f"âš ï¸ Error fetching YouTube trending: {e}")
        return []

def get_google_trends_animals():
    """
    Ø¨ÙŠØ¬ÙŠØ¨ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø§Ù„Ù„ÙŠ ØªØ±ÙŠÙ†Ø¯ Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ Ù…Ù† Google Trends
    """
    try:
        import pytrends
        from pytrends.request import TrendReq
        pytrend = TrendReq()
        pytrend.build_payload(kw_list=["animals", "wildlife", "zoo", "exotic animals"])
        related = pytrend.related_queries()
        keywords = []
        for kw in related.values():
            if kw and "top" in kw:
                keywords += [row["query"] for _, row in kw["top"].iterrows() if any(x.isalpha() for x in row["query"])]
        print(f"âœ… Google Trends found {len(keywords)} animal-related keywords.")
        return list(set(keywords))
    except Exception as e:
        print(f"âš ï¸ Google Trends error: {e}")
        return []

def get_reddit_trending_animals():
    """
    Ø¨ÙŠØ¬ÙŠØ¨ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø§Ù„Ù„ÙŠ Ø¹Ù„ÙŠÙ‡Ø§ ØªÙØ§Ø¹Ù„ Ø¹Ø§Ù„ÙŠ Ù…Ù† Reddit
    """
    try:
        headers = {'User-Agent': 'WildFactsBot/1.0'}
        res = requests.get("https://www.reddit.com/r/Animals/top.json?t=day&limit=25", headers=headers)
        posts = res.json().get("data", {}).get("children", [])
        titles = [p["data"]["title"] for p in posts]
        print(f"âœ… Reddit trending posts fetched: {len(titles)}")
        return titles
    except Exception as e:
        print(f"âš ï¸ Reddit trending fetch error: {e}")
        return []

def optimize_channel():
    """
    Ø¨ÙŠØ¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆÙŠØ¹Ù…Ù„ Ù…Ù†Ù‡Ø§ ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
    """
    print("ğŸ¤– Running Smart Optimization...")
    youtube_trends = get_youtube_trending_animals()
    google_trends = get_google_trends_animals()
    reddit_trends = get_reddit_trending_animals()

    all_trends = list(set(youtube_trends + google_trends + reddit_trends))
    if not all_trends:
        print("âš ï¸ No trending data found, using fallback animal list.")
        all_trends = get_trending_animals()

    selected = random.sample(all_trends, min(10, len(all_trends)))
    print(f"ğŸ”¥ Selected trending animals/topics: {selected}")

    # Ù†Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù„Ø´Ø§Ù† Ø§Ù„Ù€ main_long.py Ùˆ main_shorts.py ÙŠØ³ØªØ®Ø¯Ù…ÙˆÙ‡Ø§
    os.makedirs("data", exist_ok=True)
    with open("data/trending_animals.json", "w", encoding="utf-8") as f:
        json.dump(selected, f, ensure_ascii=False, indent=2)
    print("âœ… Optimization complete, results saved!")

if __name__ == "__main__":
    optimize_channel()
